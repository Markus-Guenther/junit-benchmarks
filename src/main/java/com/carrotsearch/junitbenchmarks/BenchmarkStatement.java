package com.carrotsearch.junitbenchmarks;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.Callable;
import java.util.concurrent.CompletionService;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorCompletionService;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;

import static com.carrotsearch.junitbenchmarks.BenchmarkOptionsSystemProperties.*;
import org.junit.runners.model.FrameworkMethod;
import org.junit.runners.model.Statement;

/**
 * Benchmark evaluator statement.
 */
final class BenchmarkStatement extends Statement
{
	/**
	 * Factored out as a nested class as it needs to keep some data during test evaluation.
	 * @author Dominik Drzewiecki <dominik.drzewiecki@gmail.com>
	 *
	 */
	protected abstract class BaseEvaluator
	{
        final protected ArrayList<SingleResult> results;

        final protected int warmupRounds;
        final protected int benchmarkRounds;
        final protected int totalRounds;
        
        protected long warmupTime;
        protected long benchmarkTime;
	
		protected BaseEvaluator(int warmupRounds, int benchmarkRounds,
				int totalRounds) {
			super();
			this.warmupRounds = warmupRounds;
			this.benchmarkRounds = benchmarkRounds;
			this.totalRounds = totalRounds;
			this.results = new ArrayList<SingleResult>(totalRounds);
		}

		protected GCSnapshot gcSnapshot = null;

		protected abstract Result evaluate() throws Throwable;

		protected final SingleResult evaluateInternally(int round) throws Throwable {
            // We assume no reordering will take place here.
            final long startTime = System.currentTimeMillis();
            cleanupMemory();
            final long afterGC = System.currentTimeMillis();

            if (round == warmupRounds)
            {
                gcSnapshot = new GCSnapshot();
                benchmarkTime = System.currentTimeMillis();
                warmupTime = benchmarkTime - warmupTime;
            }

            BenchmarkStatement.this.base.evaluate();
            final long endTime = System.currentTimeMillis();

            return new SingleResult(startTime, afterGC, endTime);                   
		}
		
		protected final Result computeResult() {
			final Statistics stats = Statistics.from(
		            results.subList(warmupRounds, totalRounds));

	        return new Result(
	            target, method,
	            benchmarkRounds,
	            warmupRounds,
	            warmupTime,
	            benchmarkTime,
	            stats.evaluation,
	            stats.gc,
	            gcSnapshot
	        );
		}
	}
	
	/**
	 * Performs test method evaluation sequentially.
	 * @author Dominik Drzewiecki <dominik.drzewiecki@gmail.com>
	 *
	 */
	private final class SequentialEvaluator extends BaseEvaluator
	{

		SequentialEvaluator(int warmupRounds, int benchmarkRounds,
				int totalRounds) {
			super(warmupRounds, benchmarkRounds, totalRounds);
		}
		
		@Override
		public Result evaluate() throws Throwable {
			warmupTime = System.currentTimeMillis();
	        benchmarkTime = 0;
	        for (int i = 0; i < totalRounds; i++)
	        {
	            results.add(evaluateInternally(i));
	        }
	        benchmarkTime = System.currentTimeMillis() - benchmarkTime;
	        
	        return computeResult();
		}		
	}

	/**
	 * Performs test method evaluation concurrently. The basic idea is to obtain
	 * a <tt>ThreadPoolExecutor</tt> instance (either new one on each evaluation
	 * as it is implemented now or a shared one to avoid excessive thread
	 * allocation), wrap it into a
	 * <tt>CompletionService&lt;SingleResult&gt;</tt>, pause its execution until
	 * the associated task queue is prefilled with <tt>totalRounds</tt> number
	 * of <tt>EvaluatorCallable&lt;SingleResult&gt;</tt> The prefilling and
	 * pausing is performed <i>intentionally</i> in order to avoid the noise
	 * generated by the main thread while submitting <tt>Callable</tt>s
	 * influence the proper test execution times.
	 * 
	 * 
	 * @see java.util.concurrent.ExecutorCompletionService.submit(Callable<V>)
	 * @author Dominik Drzewiecki <dominik.drzewiecki@gmail.com>
	 * 
	 */
	private final class ConcurrentEvaluator extends BaseEvaluator
	{
		private final class EvaluatorCallable implements Callable<SingleResult>  
		{
			// Sequence number in order to keep track of warmup /  benchmark phase    
			private final int i;
			
			public EvaluatorCallable(int i) {
				this.i = i;
			}
			
			@Override
			public SingleResult call() throws Exception {
	            try {
	            	latch.await();
					return evaluateInternally(i);
				} catch (Throwable e) {
					throw new Exception(e);
				}
			}
		}

		private final int concurrency;
		private final CountDownLatch latch;
		
		ConcurrentEvaluator(int warmupRounds, int benchmarkRounds,
				int totalRounds, int concurrency) {
			super(warmupRounds, benchmarkRounds, totalRounds);
			// Runtime.getRuntime().availableProcessors() might change during runtime lifetime, thus this is being evaluated before each test if required
			this.concurrency = concurrency == 0 ? Runtime.getRuntime().availableProcessors() : concurrency;
			this.latch = new CountDownLatch(totalRounds);
		}

		/**
		 * Perform ThreadPoolExecution initialization.
		 * Returns new preconfigured threadPoolExecutor for particular concurrency level and totalRounds to be executed
		 * Candidate for further development to mitigate the problem of excessive thread pool creation/destruction. 
		 * @param concurrency
		 * @param totalRounds
		 * @return
		 */
		private final ExecutorService getExecutor(int concurrency, int totalRounds) 
		{
	    	return new ThreadPoolExecutor(concurrency, concurrency, 10000, TimeUnit.MILLISECONDS, new ArrayBlockingQueue<Runnable>(totalRounds));
		}

		/**
		 * Perform proper ThreadPool cleanup. For <tt>ThreadPoolExecutor</tt>
		 * created on each test evaluation should just shutdown it. Should the
		 * <tt>Excutor</tt> be obtained from somewhere else, thus avoiding
		 * unnecessary thread creation/destruction, some other proper cleanup
		 * need be done (possibly drain the execution queue if the exception was
		 * thrown ?)
		 * 
		 * @param executor
		 */
		private final void cleanupExecutor(ExecutorService executor)
		{
        	List<Runnable> pending = executor.shutdownNow();
        	//System.out.println("Shutdown: " + System.currentTimeMillis() + ", pending: " + pending.size());	
		}
		
		@Override
		public Result evaluate() throws Throwable {
			// Obtain ThreadPoolExecutor (new instance on each test method for now)
			ExecutorService executor = getExecutor(concurrency, totalRounds);
	    	CompletionService<SingleResult> completed = new ExecutorCompletionService<SingleResult>(executor);

	        for (int i = 0; i < totalRounds; i++)
	        {
	        	completed.submit(new EvaluatorCallable(i));
	        	latch.countDown();
	        }
	        
	        warmupTime = System.currentTimeMillis();
	        benchmarkTime = 0;
	        try {	       
		        for (int i = 0; i < totalRounds; i++) {
		        	results.add(completed.take().get());
		        }
	        }
	        catch (ExecutionException e) {
	        	// Unwrap (twice!) the original Throwable thrown by the tested method 
	        	throw e.getCause().getCause();
			}
	        finally {
	        	// Assure proper executor cleanup either on test failure or an successful completion
	        	cleanupExecutor(executor);
	        }
	        benchmarkTime = System.currentTimeMillis() - benchmarkTime;
	        return computeResult();
		}		
	}
	
    /**
     * How many warmup runs should we execute for each test method?
     */
    final static int DEFAULT_WARMUP_ROUNDS = 5;

    /**
     * How many actual benchmark runs should we execute for each test method?
     */
    final static int DEFAULT_BENCHMARK_ROUNDS = 10;

    /**
     * How many threads should execute tests concurrently?
     * @see BenchmarkOptions.concurrency()
     */
    final static int DEFAULT_CONCURRENCY = -1;
    
    /**
     * If <code>true</code>, the local overrides using {@link BenchmarkOptions} are
     * ignored and defaults (or globals passed via system properties) are used.
     */
    private boolean ignoreAnnotationOptions = Boolean
        .getBoolean(IGNORE_ANNOTATION_OPTIONS_PROPERTY);

    /**
     * Disable all forced garbage collector calls.
     */
    private boolean ignoreCallGC = Boolean.getBoolean(IGNORE_CALLGC_PROPERTY);

    private final Object target;
    private final FrameworkMethod method;
    private final Statement base;
    private final BenchmarkOptions options;
    private final IResultsConsumer [] consumers;

    /* */
    public BenchmarkStatement(Statement base, FrameworkMethod method, Object target, 
        IResultsConsumer... consumers)
    {
        this.base = base;
        this.method = method;
        this.target = target;
        this.consumers = consumers;

        this.options = resolveOptions(method);
    }

    /* Provide the default options from the annotation. */
    @BenchmarkOptions
    @SuppressWarnings("unused")
    private void defaultOptions()
    {
    }

    /* */
    private BenchmarkOptions resolveOptions(FrameworkMethod method)
    {
        // Method-level override.
        BenchmarkOptions options = method.getAnnotation(BenchmarkOptions.class);
        if (options != null) return options;

        // Class-level override. Look for annotations in this and superclasses.
        Class<?> clz = target.getClass();
        while (clz != null)
        {
            options = clz.getAnnotation(BenchmarkOptions.class);
            if (options != null) return options;

            clz = clz.getSuperclass();
        }

        // Defaults.
        try
        {
            return getClass().getDeclaredMethod("defaultOptions").getAnnotation(
                BenchmarkOptions.class);
        }
        catch (Exception e)
        {
            throw new RuntimeException(e);
        }
    }

    /* */
    @Override
    public void evaluate() throws Throwable
    {
        final int warmupRounds = getIntOption(options.warmupRounds(),
            WARMUP_ROUNDS_PROPERTY, DEFAULT_WARMUP_ROUNDS);

        final int benchmarkRounds = getIntOption(options.benchmarkRounds(),
            BENCHMARK_ROUNDS_PROPERTY, DEFAULT_BENCHMARK_ROUNDS);

        final int concurrency = getIntOption(options.concurrency(),
                CONCURRENCY_PROPERTY, DEFAULT_CONCURRENCY);
        
        final int totalRounds = warmupRounds + benchmarkRounds;

		final Result result = ((concurrency == -1) ? new SequentialEvaluator(
				warmupRounds, benchmarkRounds, totalRounds)
				: new ConcurrentEvaluator(warmupRounds, benchmarkRounds,
						totalRounds, concurrency)).evaluate(); 

        for (IResultsConsumer consumer : consumers)
            consumer.accept(result);
    }
    
    /**
     * Best effort attempt to clean up the memory if {@link BenchmarkOptions#callgc()} is
     * enabled.
     */
    private void cleanupMemory()
    {
        if (ignoreCallGC) return;
        if (!options.callgc()) return;

        /*
         * Best-effort GC invocation. I really don't know of any other way to ensure a GC
         * pass.
         */
        System.gc();
        System.gc();
        Thread.yield();
    }

    /**
     * Get an integer override from system properties.
     */
    private int getIntOption(int localValue, String property, int defaultValue)
    {
        final String v = System.getProperty(property);
        if (v != null && v.trim().length() > 0)
        {
            defaultValue = Integer.parseInt(v);
        }

        if (ignoreAnnotationOptions || localValue < 0)
        {
            return defaultValue;
        }

        return localValue;
    }
}